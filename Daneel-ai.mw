daneel-ai is a rule-based AI (to be) written in Python. The bot framework is designed to be ruleset-agnostic, with components that should be implemented per ruleset and per desired behavior. More info on the [[User:Iwanowitch/RFTS_AI_proposal|proposal page]] (this will be merged here in time).

== Overview ==
At the start of a turn, the bot downloads the universe data from the server and stores them in a local cache. It then enters the initialization phase. Based on the ''initialization rules'', the cache is read and constraints are added to the constraint store. The next phase is the resolution phase. The bot uses the constraints to deduce new knowledge about the system via ''resolution rules'' and adds it to the store. This is the bulk of the work. Afterwards, the finalization phase searches for constraints that signify orders to be executed and creates the appropriate orders.  As such, the resolution phase can be seen as a process that transforms the state of the game to actions to be performed, with the initialization phase providing the state and the finalization phase executing the actions.

== Design ==
The bot is based on libtpclient-py to handle the connection to the server and the cache of game objects. Furthermore, the client is designed to be modular, each of the 3 phases can be changed to another implementation to allow ruleset-specific information to be considered, or to change the strategies of the AI.

=== Initialization phase ===
The initialization phase pretty much copies the object hierarchy from the cache into the constraint store. This means that for example constraints of the form <code>planet(5)</code> and <code>location(5,0,100032,0)</code> will be added. The exact way this will happen still needs investigation, if possible some reflection should be used.

=== Resolution phase ===
Now the AI has a bunch of facts about the world and wants to deduce a battle plan from them. We give him a set of rules to apply to the constraint store. The idea of these rules is based on [http://www.cs.kuleuven.be/~dtai/projects/CHR/ CHR]. An example of a rule would be "if the constraint resources(X) exists and X > 500, then remove that constraint and add the constraints resources(X-500) and order_build_ship()".

The exact way to represent these rules still has to be decided on. Probably the Interpreter design pattern will be used, together with a parser that reads CHR syntax which is pretty concise for these types of rules. It should be noted that it is necessary to allow arbitrary Python statements to appear inside these rules. Although CHR is Turing complete, you don't want to implement "calculate_distance_to" using nothing but constraints.

=== Finalization phase ===
When no more rules can fire because the preconditions don't match with the constraint store, the algorithm enters the finalization phase. The store is checked for predicates of a certain form (probably order_move and order_build etc), picks those out and executes the required actions.

== Constraint syntax/semantics ==
The program keeps track of a multiset of facts, called constraints. These facts are represented by predicates, possibly with parameters - those familiar with Prolog will be at home. It is important to note that facts might be parameterized with logical variables, that is, variables that don't have an assignment yet (a so-called non-ground variable). For example, if the fact <code>solution(X)</code> is in the constraint store, this asserts that there exists a solution X, which might be unified with a concrete value later on. This is useful for abstract reasoning and search strategies.

The exact syntax as it will be in the bot still needs some thinking out. For now, I use some mix of Python and Prolog in this document. In CHR syntax, a general rule looks like this:
 name @ kept \ removed <=> guard | body
The ''name'' is an optional string, mostly to ease debugging and possibly useful for reflection, although that needs to be researched. The <code>kept \ removed</code> part is also named the ''head''. Both of those parts are optional. If there is no kept part, we talk about a ''simplification rule'', if there is no removed part, we talk about a ''propagation rule'' (for clarity, we write propagation rules as <code>kept ==> body</code>), if they are both there it is a ''simpagation rule'' and if none of them are there it's just a fact to be added to the constraint store, so it's not really a rule. The head consists of a conjunction of constraints only, the guard of Python code, and the body can contain a mix of both. Note that all Python calls need to be done with ground variables.

As an example, the rule from above:
 buildships @ resources(X) <=> X > 500 | resources(X-500); order_build_ship
A way to enforce set semantics (no duplicates) for a predicate:
 predicate \ predicate <=> pass
A canonical CHR example is the less-then-or-equal relationship (basically, any partial ordering). Note that = means logical unification and can work in both ways:
 reflexivity @ leq(X,X) <=> pass
 antisymmetry @ leq(X,Y) and leq(Y,X) <=> X = Y
 transitivity @ leq(X,Y) and leq(Y,Z) ==> leq(X,Z)

The algorithm matches each head to the constraint store in turn. If a match is found, the guard is checked. If it is found to evaluate to True in bool context, the rule ''fires''. The constraints that match the removed part are removed from the store, and those in the body are added to the store. The rules are then tried again from the beginning. This is the naive way of doing the matching, but if needed improvements are possible.

To extend the standard example, assume the rules are the three leq rules defined above, and let the constraint store hold the three facts <code>leq(A,B),leq(B,C),leq(C,A)</code>. The transitivity rule will fire and add <code>leq(C,A)</code> from <code>leq(A,B),leq(A,C)</code>. Then the antisymmetry rule will assert that A = C. The reflexivity rule will remove <code>leq(C,A)</code> and <code>leq(A,C)</code> since A = C. The antisymmetry rule will make A=B and reflexivity will remove the remaining constraints. We end with an empty constraint store and the knowledge that A=B=C.

If I have time and the need arises, I might implement parts of proposed extensions of CHR, like rule priorities, negation by absence, and aggregates support (which allows constructs like sum, min, max to appear in rules). It should be noted that these constructs can be implemented with the existing structure, but for clarity it doesn't hurt to have these extension. There might be the need to implement a few Prolog-like predicates that allow efficient work with non-ground variables, this will become clear when coding. If the program turns out to be too slow, the naive matching algorithm can be changed to the more advanced Rete algorithm that builds a graph of which rules to try when constraints are changed, dramatically speeding up the matching. Other algorithms might also be possible (TREAT, LEAPS), but I've never met these before so I'll have to do some research. Changes in the data structures underlying the constraint store and the rules might also provide speedup.

== Milestones ==
* <s>Client that can connect to the server</s>
* <s>Constraint representation</s>
* <s>Logical unification support</s>
* <s>Constraint store</s>
* Rule representation
* Rule parsing
* Rule store
* Rule engine complete
* Client can extract orders from the constraint store and send them to the server
* Get some sensible behavior

== Planning ==
Current planning already differs significantly from my original planning and will probably keep on changing. In my original plan, I envisioned the rule matching to be something very basic and writing the rules themselves to be hard. I changed that around after some research, after all, it seems more sensible to do as much work as possible on the framework to make rule creation/experimentation as easy as possible. Also, my exams are more painful than I thought they would be :(

2008-05-31 - 2008-06-06: Get constraint matching to work.<br>
2008-06-07 - 2008-06-17: Serious study time. Sorry. Though I should get the constraint store working.<br>
2008-06-18 - 2008-06-22: Implement rule representation.<br>
2008-06-23 - 2008-06-26: Implement rule store.<br>
2008-06-26: Basic rule engine in place (test: add basic rules to move the scout around the universe).<br>

2008-06-26 - 2008-07-06: Gone. Probably won't have any time for SoC.<br>
2008-07-07: Start of mid-term evaluation. I kindly ask nash to wait with giving me bad marks for a few more days as I basically just start coding.<br>
2008-07-07 - 2008-07-20: Rule implementation. Will also involve some iterations of refining the engine to allow more flexible rule sets (and fix bugs).<br>
2008-07-20: Rules written, tested, working.<br>

2008-07-20 - 2008-07-24: Toy around with the rule engine, trying to create a some interesting behavior by hand.<br>
The following only applies if the schedule works out and there are no huge setbacks.<br>
2008-07-25 - 2008-07-31: Design of the genetic algorithm (textbook stuff), setup of testing environment (server configuration, being able to get stats from it, etc).<br>
2008-08-01 - 2008-08-09: Genetic algorithm running, hopefully yielding even more good and interesting behavior.<br>
2008-08-10 - 2008-08-16: Akademy, in my country, so I'll probably be there.<br>
2008-08-11: Pencils down date, genetic algorithm around AI working and yielding some good results.

== TODO ==
These are my direct TODOs, mostly for myself to see what I'm supposed to be doing at this moment instead of reading the wiki. The milestones part might be more interesting to other readers.
* Finalize design
** Draw out the full design because it's a bit messy in my head right now
** Think about rule representation
** Find a sensible way to add weights to rules. This would change the semantics of CHR to a nondeterministic algorithm, so this needs a bit of consideration (not urgent, this is an extension for the rule implementation phase)
* Coding
** Create constraint store
** Add initial facts from cache to store
