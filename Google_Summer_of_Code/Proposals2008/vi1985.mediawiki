== '''''Genetic Conquest''' (henceforth, GC)'', an AI Client for Thousand Parsec: Proposal     '''''<<<FINALIZED>>>'''''==

This document provides a general overview of the initial design concept of the AI client (GC) I want to design for Thousand Parsec. The AI agent will be written in Java, since it is the language I'm proficient with, and hence will use the libtpproto-java library. [EDIT: corrected from the previously reverse formulation --vi1985 10:51, 25 March 2008 (EDT)] Upon completion, the AI Client will be able to successfully play the RFTS ruleset, and with slight modifications to some of its modules, GC will be able to play any other TP ruleset.

*Please feel free to make suggestions/corrections in the discussion section, and in the space provided below!!

== Deliverables / Goals ==

The goal of this project is to devise and implement an efficient and capable AI Client for Thousand Parsec. The main focus I have set for myself is in designing and implementing the AI agent architecture and logic (consistent with TP03 protocol), and secondary to that is the completion of a discrete and working AI Client in time for the due date. Both goals are to be considered deliverables, but the relative importance of each is highlighted for clarity of communication. Thus, more formally the deliverables will consist of:

*Design and implement the AI agent for TP in Java.
*Integrate it with the libtpproto-java library.
*Create a convenient and comprehensive UI for the AI client, for pre-game adjustments.
*Collaborate on completing the libtpproto-java library with jezuch, in the direction of finalizing a complete and discrete AI Client.

== Planning and Progress ==

'''Timeline (Big Checkpoints)'''

*April 12 - My exams finish; Begin active study of libraries, ruleset, and other relevant materials.
*April-May - Finalize the design scheme.
*beginning of May - Start coding.
*July 7 - Have AI agent ready in time for mid-term evaluations.
*Mid July - Have the GUI ready for the client. [EDIT: as jezuch noticed, it would probably be better to make it a primarily a command-line interface. So, if everything goes well, I can probably make an optional GUI interface, but this now turns into an optional deliverable --[[User:Vi1985|vi1985]] 10:52, 25 March 2008 (EDT)]
*August 11 - Complete AI agent - client library integration, have a complete and ready to use Java AI Client, and still have a buffer week for "pencils down" date.

'''General Considerations'''

I don't see this as a May 26-August 18 project. Rather, I'll start working on it full time beginning in April, finish the core coding by August 11, and then slowly work to complete the desired set of features from then on. I definitely see this as a project I can slowly build on, rather than just a summer contract. I will be taking one university subject this summer, but I should have more than enough time for full-time development, and for studying.  I plan on spending at least 30 hrs/wk for coding, and of course many more will go on planning, reading relevant materials and communicating. There are no week-long vacations planned for the summer, although on some weekends I may be unavailable.

'''Disaster Contingencies'''

As mentioned above, I will have two high-priority obligations for the summer: this project, and a single university subject. There should be ample time to delegate to each. A preemptive strategy to counter unexpected situations would be to divide the task into three parts: first design and implement the AI agent, with reliance on the libtpproto-java library (Deadline: July 7), create a comprehensive GUI, by means of which the players will be able to fully configure the AI agent, and only then do the general work of creating a discrete and (as much as possible!) complete AI Client, using the AI agent, and the libtpproto-java library. If something unexpected were to occur during the summer, then at least the core features and logic would have hopefully been completed.

'''Work Progress Log and Communication'''

I plan to start a blog to document my progress, as well as making it a place for general thought tangents relevant to the project. I also intend to be available on the IRC channel as much as possible, and generally communicate with the other members of the TP project as much as necessary. I believe a good policy of code submission would be to do it on a regular weekly basis, but this is up to the project mentors to have final say on.

== Benefits to Thousand Parsec, and its community of Users==

A worthy AI Client would enrich the game experience in cases where only a small number of people can have a game together. In the TP RFTS-clone[[http://www.thousandparsec.net/wiki/TP_RFTS]], there is a hard-coded number of players, which must participate in the game. That means that having a good AI Client will make games of less than four human players not only possible, but enjoyable [EDIT: This info is obsolete; There is only a max. number of players, no restrictions on minimum. Still, the argument holds--[[User:Vi1985|Vi1985]] 21:36, 24 March 2008 (EDT)] . This particular design (see below) ensures inherently creative solutions, which would make it hard to "crack" and trap. These features are bound to add to gameplay quality, as human players will strive not only to outsmart each other, but will also struggle with the AI player. The fact that I chose to code it in Java will make it easy to set up on any machine.

== Design Principles ==

'''General Execution Sequence:'''

* Turn start: receive "universe-picture" from server.
* Extract info from the universe-picture.
* Run core genetic algorithm, which would return the set of actions to be performed this turn.
* Communicate actions back to server.


'''Description and Virtues of A Genetic Algorithm Solution'''

I chose a genetic algorithm (GA) implementation of the AI agent for several reasons. First of all, it is perfectly suited for the role in TBS games, since is involves a progressive refinement of "hypotheses", until a suitable one has been reached, in a 
"contemplative" manner, rather than in a quick, just-in-time fashion. Basically, it will model and evaluate outcomes of its own actions and opponent replies for several moves ahead, then progressively improve the whole move-sequence, utilizing the power of evolution to come up with good solutions. Since it is looking many moves ahead, and considering the whole move-sequence at once, the solutions it comes up with aren't obvious "quick-fixes", but genuine strategy. Together with a heuristic to predict opponent-moves, this algorithm will make the AI relatively sensitive to traps, and hard to fool. Another bonus is that the solutions it comes up with will be creative ones, since there will be no hard-coded templates on which it will rely in decision making. This will ensure that it will always be a creative and unpredictable opponent! Finally, a GA design will make the algorithm highly modular, and ensure quick transitions between rulesets. 

The main difficulty I expect to encounter will be in making a good heuristic for predicting opponent moves (henceforth OMM, Opponent Move Module). Careful analysis will have to be done to estimate what should a reasonable player do, based on its assets, and the positioning on the map relative to others. Then a small set of rules (possibly probabilistic ones!) will be extracted, and implemented as the OMM. I will try my best to incorporate elements of machine learning and inference making into the module, so that the AI agent will be simulating games against opponents similar to the real ones, when deciding on strategy. A further layer of heuristics will have to be used, as the information available to the player will be incomplete. I will not be able to utilize the same genetic algorithm to calculate opponent moves, since embedded GA's tend to run out of memory very quickly (actually, the recursion would never terminate, or else a good heuristic for opponent moves will have to be implemented at some point, which makes this an exercise in futility!). 

''Possible Alternatives to a GA Solution''

I would rather not simply use a set of heuristics and behavioral tendencies as my decision making module, since having it look several moves ahead would most likely entail creating an alpha-beta decision tree, then proceeding by the Paranoid Hypothesis assumption (likely is the best heuristic, since there are 4, not 2 players), which will be much more memory- and execution-time guzzling, and much less accurate, than a well designed GA. Another alternative would be to have rules to calculate a solution a single [move] in advance. While it may be a good quick-fix, it will not offer the more advanced (and intelligent) player a challenge, and furthermore its simple strategy would damage gameplay quality.

'''The Evolutionary Paradigm'''

''Hypotheses:''

The GA will operate on "hypotheses", which are basically encoded move-sequences. Each such hypothesis will be a 4D array (x-axis: encoding moves ahead (1... search_depth); y-axis: available action categories, e.g. development, purchasing, invading, etc. The logic for that is to say, for example, I want to have a maximum of 2 technology moves, 3 industry moves, 1 send fleet move, etc.; w-axis: division by planets owned and by current fleet on the move (max. value will vary in accordance with situation); z-axis: a uniquely-encoded set of actions (one set per each category). 

Such encoding ensures complete coverage, is compact and is easy to operate upon. Every point in the 4D array corresponds to some action, in some action-class, on some planet or some fleet, in some future move. In each hypothesis, the x and y-values (number of moves, action categories) will always be fixed, the w-values will change in accordance with how many planets the player owns, and the only thing that can mutate are z-values (according to some restrictions, of course).

''Generations:''

The GA algorithm will start with an init_seed, which is a hypothesis. At the start of the game the init_seed will be determined by the opponent-predictor module [EDIT: I meant the OMM --[[User:Vi1985|Vi1985]] 21:41, 24 March 2008 (EDT)], which will provide a decent strategy to build on, then at each subsequent turn, the winning hypothesis of the previous turn will be modified to serve as the next turn's init_seed (the modification: shift all 3D <y,z,w> slices one to the left on the x-axis; randomly generate the last one [EDIT: I decided it is better to use the OMM to generate the last move in the init_seed, thus giving it a good start. This way, I can cut on the production of new generations to find good solutions, and still retain creativity in the solutions it comes up with --[[User:Vi1985|vi1985]] 10:58, 25 March 2008 (EDT)]). 

The init_seed will then mutate (z-values will mutate in several random points (probably using the normal mutation rate), with compliance to restrictions), to create 3 generation_seeds. Each generation of mutations, there will be 3 generation_seeds, to preserve a variety of solutions, but on the other hand, not be too computationally-heavy. From each such generation_seed there will evolve three populations: a risk population (high mutation-rate, to seek solutions outside the local maximum), a normal population (moderate mutation rate, with reasonable search-power of solutions), and a conservative population (low mutation rate, to preserve good solutions). Then, each hypothesis will be decoded, simulated, and evaluated. From each population, the best hypothesis will make it to the next selection (9 in all). To prevent loss of good solutions, the generation_seeds will automatically be added to this round of selection (total: 12). Then, the 3 best ones will be selected as the next generation_seeds. 

The process of making new generations will happen a fixed number of times (for a fixed and reasonable execution-time), or until some hypothesis promises a win, and at the end returns the best one. I will have to play around with the numbers, to have the AI take less than 2 minutes to complete its turn. (//Your suggestions as to the time an AI should reasonably take to find a solution?//). Then, the actions specified in the first move of the winning hypothesis are sent back to the server for execution.

''Fitness function:''

A fitness function will be derived to give each hypothesis a numeric evaluation, by which they can be compared (e.g. higher = better, or closer to zero = better). This function will have as parameters the current stats of the AI player, its relative standing in the universe compared to others (number of planets, fleets, etc), and the winning conditions of the ruleset in question (here, RFTS). A heuristic will have to be used, as the information available to the player will be incomplete.

'''User Interface'''

I wish to make the AI-agent as fully configurable as possible. Although it is impossible to deterministically predict and influence its behavior, some important features can be played around with:
*Difficulty: This can simply be a function of search depth of the generated hypotheses, of the size of the generation, and/or of the number of generations the algorithm will go through, before outputting a solution.
*Changes to the opponents AI modules, which will alter the opponents the GA will be simulating playing against. This can be useful if a player wants a serious challenge. In that case, the player would tweak the opponent-module to play similarly to him(her).

The UI can either be text or GUI. When working on the AI agent, I will use the console command line, but then I plan to implement an MVC GUI module [EDIT: as jezuch noticed, it would probably be better to make it a primarily a command-line interface. So, if everything goes well, I can probably make an optional GUI interface, but this now turns into an optional deliverable --vi1985 10:52, 25 March 2008 (EDT)]. An important note is that I only see usefulness in a UI prior to game start, so there is no reason to keep it running during the game. ///perhaps anyone has some idea of usefulness of AI manipulation during the game? I can't think of anything at the moment.///

== Future Directions for ''Genetic Conquest'' ==

Endless work can be put in optimizing an optimization algorithm :). The most interesting and promising directions for future work I can see from this disadvantaged point are:

*OMM (Opponent Move Module) Optimization: Quite possibly the most interesting and useful direction to consider, it to provide the OMM with advanced machine-learning capabilities, directed at analyzing visible opponent behavior. This will highly optimize the selection process of hypotheses, since the games being simulated will be with opponents very similar in behavior to real ones. To that end, neural nets could be used for a robust and generic solution. ''I would be very interested in conducting further work in that avenue!''
*Evolutionary Paradigm Optimization: The above evolutionary paradigm is robust and efficient, but it is far from perfect. Even more creative evolutionary solutions can be found, for example combining evolution and dynamic tree structures, or just changing the paradigm altogether. 
*Ruleset Compliance: I intend for the design to be highly modular, so that it would be straightforward to have the AI agent comply to different rulesets. Probably the best option would be to create a library for each such ruleset, and modify some aspects of the AI accordingly (i.e. the Fitness function, define permissible actions, OMM restrictions and characteristics, and other small things).
*Other? As far as I can see, these are the main avenues for improvement, although as I said above, you can work forever on optimizing an optimization algorithm.

== About me ==

My name is Victor Ivri (forum and IRC: vi1985). I'm double majoring in Computer science and Cognitive science at York U, Toronto, Canada. My main interest is in the area of AI. I'm interested in both practical implementations of various forms of AI, and in the philosophical and psychological underpinnings of it. I heard of genetic algorithms not too long ago in a Cognitive science conference, ran home, read about how it's done, and built a few (increasingly elaborate) examples myself. I'm really excited at this opportunity to participate in the development process of a 4X game, since I'm a huge fan of both TBS and RTS. I don't have a lot of time for game-playing at the moment, but I still occasionally meet with friends to play HMM3 into the night (or morning) :). 

I want to do this project because it is very interesting and challenging. It is a great opportunity for me to advance my knowledge base and practical skills in my area of interest, as well as gain experience in the opensource community, and I will work very hard to achieve a successful and working result before the deadline. In the time elapsed since I first heard of TP (not more than a week!), I've had the pleasure to talk and exchange ideas with many of you, and I hope that our collaboration will continue into the future, since this is definitely a project I (and others) can build and elaborate on. Even more than that, I hope that you give me a chance to prove that my ideas and skills are an asset to Thousand Parsec.

'''Programming Example''': 
Here's a rather simple, but neat, example of genetic programming (a day's worth of hacking), which solves a class of non-trivial problems in arithmetic. It is of a quite different design than explained above, but it illustrates how "letting evolution run its course" can solve non-trivial problems. Here is the link: [http://www.4shared.com/account/file/41671485/10b80908/genArithmetic.html]. I have started slowly working on a checkers AI that implements the design above for testing purposes, but I'm afraid it won't be ready soon due to university workload.

'''Contact info''': victor.ivri AT gmail DOT. com


Thank you for considering my candidacy.

== Your Comments Here ==

Very nice proposal, the design is explained in quite a lot of detail. I think in the application you will submit thru the Google webform you can shorten it and make it more compact, but it is great to have it like this on the wiki.

You should also make timeline a bit more detailed in the application and describe GUI a bit more. A some kind of risk management section should also be there: what kind od problems could arise (in coding, life) and what are your plans to deal with these problems.

You also mention that you have already done some examples. It would be a plus if you could provide a link to the source code or examples.

Into application you could also include information if you already have a blog or some other page where you would write about your progress.

Oh yeah and write down what benefits your project brings to TP and game players. Also mention in the application how many hours a week you will be working on this and if you have any other commitments during GSoC period, Maybe you will be on vacation for a few days?

I think this is enough for now from my part. Keep up the great work!
--[[User:JLP|JLP]] 11:13, 23 March 2008 (EDT)

>>>Thank you for your suggestions, JLP. I will put some source code online, and expand on the areas that you mentioned. --[[User:Vi1985|Vi1985]] 11:59, 23 March 2008 (EDT)

>>>Done. --[[User:Vi1985|Vi1985]] 16:12, 23 March 2008 (EDT)


"there is a hard-coded number of players, which must participate in the game"

- Not exactly. This is true of the standard RFTS but is one of the differences for TP RFTS- it has no min players, only a max. Btw, I've made trivial updates to the TP RFTS wiki page.
--[[User:Xdotx|Xdotx]] 21:01, 24 March 2008 (EDT)

>>>Xdotx: Thanks for the update! I have actually caught it about 30mins ago, and made a comment about it in my Google proposal ;). I should change it here as well... --[[User:Vi1985|Vi1985]] 21:31, 24 March 2008 (EDT)