== '''''Genetic Conquest''' (GC)'', an AI Client for Thousand Parsec: Proposal ==

'''Abstract'''

This document provides a general overview of the design concept of the AI client I intend to design for Thousand Parsec. The core design of the AI agent would be a genetic algorithm, which would enforce natural selection of game-hypotheses, and come up with an optimized solution. Each hypothesis would be simulated against an AI opponent, and the outcome will be evaluated at the end of the simulation. This design is inherently creative and robust, since it does not rely on templates for deciding on course of action. After the core design would be coded and tested, I will integrate it with an existing client library, for the purpose of creating a discrete and functional AI Client. 

The project will be implemented in Java, since it is the language I'm proficient in, and hence will use the libtpproto-java library. Upon completion, the AI Client will be able to successfully play the RFTS ruleset, and with slight modifications to some of its modules, GC will be able to play any other TP ruleset. 



*Please feel free to make suggestions/corrections in the discussion page and in the space provided below!!

== Deliverables / Goals ==

The goal of this project is to devise and implement an efficient and capable AI Client for Thousand Parsec. The main focus I have set for myself is in designing and implementing the AI agent architecture and logic (consistent with TP03 protocol), and secondary to that is the completion of a discrete and working AI Client in time for the due date. Both goals are to be considered deliverables, but the relative importance of each is highlighted for clarity of communication. Thus, more formally the deliverables will consist of:

*Design and implement the AI agent for TP in Java.
*Integrate it with the libtpproto-java library.
*Create a convenient and comprehensive UI for the AI client, for pre-game adjustments. Would utilize the console as a base, and optionally include a GUI, which can be activated by a console command (not by automatic pop-up).
*Collaborate on completing the libtpproto-java library with jezuch, in the direction of finalizing a complete and discrete AI Client.
*Fully document the process both in javadoc, and create a separate volume of comprehensive and coherent documentation.

== Planning and Progress ==

'''Roadmap (Big Checkpoints)'''

''Note that the timeline will become much clearer, and much more detailed, during the initial study and software-design period. I expect it to be firmly set by end of April.''
*'''''Initial period of learning and Software Design''''':
*April 12 - My exams finish; Begin active study of libraries, ruleset, and other relevant materials.
*By April 30 - Finalize the design scheme.
*'''''Coding I''''':
*By June 14 - Have the core genetic algorithm and AI agent ADT running and tested.
*By July 7 - Have the Opponent Simulation Module (OSM) running and tested in time for mid-term evaluations.
*'''''Coding II''''':
*By July 15 - Complete work on AI Agent, run integration tests, and start working on having a complete and functional AI Client.
*By August 11 - Finish and test AI agent/client library integration, have a complete and ready to use Java AI Client. Integration testing completed.
*'''''Final touches and documentation''''':
*By August 18 - Polish relevant documentation, and do some final touches on the code.

'''General Considerations'''

I don't see this as a May 26-August 18 project. Rather, I'll start working on it full time beginning in April, finish the core coding by August 11, and then slowly work to complete the desired set of features from then on. I definitely see this as a project I can slowly build on, rather than just a summer contract. I will be taking one university subject this summer, but I should have more than enough time for full-time development, and for studying.  I plan on spending at least 35 hrs/wk for coding, and of course many more will go on planning, reading relevant materials and communicating. There are no week-long vacations planned for the summer, although on some weekends I may be unavailable.

'''Disaster Contingencies'''

As mentioned above, I will have two high-priority obligations for the summer: this project, and a single university subject. There will be ample time to delegate to each. I do not foresee anything that can possibly interfere with the work on the project, but my preemptive strategy to counter unexpected situations would be to divide the task into three parts: first design and implement the AI agent, with reliance on the libtpproto-java library, and then work towards finishing the AI Client, using the AI agent and the libtpproto-java library, and then the final integration-testing and polishing period. If something unexpected were to occur during the summer, then at least the core features and logic would have hopefully been completed, and the code available together with documentation.

'''Work Progress Log and Communication'''

I plan to start a blog to document my progress, as well as making it a place for general thought tangents relevant to the project. I also intend to be available on the IRC channel as much as possible, and generally communicate with the other members of the TP project as much as necessary. I believe a good policy of code submission would be to do it on a regular weekly basis, but this is up to the project mentors to have final say on.

== Benefits to Thousand Parsec, and its community of Users==

A worthy AI Client would enrich the game experience in cases where only a small number of people can have a game together. This particular design (see below) ensures inherently creative solutions, which would make it hard to "crack" and trap. These features are bound to add to gameplay quality, as human players will strive not only to outsmart each other, but will also struggle with the AI player. This is a project that has much growth potential, as outlined in the relevant section below. There are a couple of advantages advantage to making it in Java: For one, there is the ease of creating comprehensive documentation (javadoc); then,there is a high cross-platform portability the client will inherently have.

== Design Principles ==

'''Design and Testing Philosophy'''

My vision is that this AI client should be highly modular, and designed from the top-down. A well planned, careful design would serve as the start point for coding. Having created the necessary stubs for classes, methods, and fields, I will proceed with a flexible, iterative approach to coding, which will allow me to have an overall vision of which data-structures should be used to ensure efficient inter-module communication, and generally low overhead. I intend to follow the timeline previously outlined, and focus on the modules which need to be completed for deadline. I intend to run unit tests twice: First, do a top-down test with dummy-values prior to implementation, and then I plan to run black-box unit tests when coding for the module is done.


'''General Execution Sequence:'''

* Turn start: receive universe object from server.
* Extract info from the universe object.
* Run core genetic algorithm, which would return the set of actions to be performed this turn.
* Communicate actions back to server.


'''Description and Virtues of a Genetic Algorithm Solution'''

I chose a genetic algorithm (GA) implementation of the AI agent for several reasons. First of all, it is perfectly suited for the role in TBS games, since is involves a progressive refinement of "hypotheses", until a suitable one has been reached, in a "contemplative" manner, rather than in a quick, heuristic fashion. Basically, it will simulate and evaluate outcomes of its own actions and opponent replies for several moves ahead, progressively improving the planned actions in future moves _as a whole_ (instead of utilizing a "greedy" solution), utilizing the power of evolution to come up with good and original solutions. Since it will be looking many moves ahead, and considering the whole move-sequence at once, the solutions it comes up with aren't obvious "quick-fixes", but genuine strategy. Together with a heuristic to predict opponent-moves, this algorithm will make the AI relatively sensitive to traps, and hard to fool. Another bonus is that the solutions it comes up with will be creative ones, since there will be no hard-coded templates on which it will rely in decision making. This will ensure that it will always be a creative and unpredictable opponent! Finally, a GA design will make the algorithm highly modular, and ensure quick transitions between rulesets. 

'''''Possible Alternatives to a GA Solution'''''

I would rather not simply use a set of heuristics and behavioral tendencies as my decision making module, since having it look several moves ahead would most likely entail creating an alpha-beta decision tree, then proceeding by the Paranoid Hypothesis assumption (likely is the best heuristic, since there are 4, not 2 players), which will be much more memory- and execution-time guzzling, and much less accurate, than a well designed GA. Another alternative would be to have rules to calculate a solution a single move in advance. While this may be a good quick-fix, and be suited as a training tool for inexperienced players, it will not offer the more advanced (and intelligent) player a challenge, and furthermore its simple strategy would damage gameplay quality.


'''Opponent Simulation Module (OSM)'''

The main difficulty I expect to encounter will be in making a good heuristic for predicting opponent moves (henceforth OSM, Opponent Simulation Module). Careful analysis will have to be done to estimate what should a reasonable player do, based on its assets, and the positioning on the map relative to others. Then a small set of rules (possibly probabilistic ones) will be extracted, and implemented as the OSM. I will try my best to incorporate elements of machine learning and inference making into the module, so that the AI agent will be simulating games against opponents similar to the real ones, when deciding on strategy. A further layer of heuristics will have to be used, as the information available to the player will be incomplete. I will not be able to utilize the same genetic algorithm to calculate opponent moves, since embedded GA's tend to run out of memory very quickly (actually, the recursion would never terminate, or else a good heuristic for opponent moves will have to be implemented at some point, which makes this an exercise in futility!). 


'''The Evolutionary Paradigm'''

'''''Hypotheses: The basic objects of the algorithm:'''''

The GA will operate on "hypotheses", which are basically encoded move-sequences. Each such hypothesis will be a 4D array (x-axis: encoding moves ahead (1... search_depth); y-axis: available action categories, e.g. development, purchasing, invading, etc. The logic for that is to say, for example, I want to have a maximum of 2 technology moves, 3 industry moves, 1 send fleet move, etc.; w-axis: division by planets owned and by current fleet on the move (max. value will vary in accordance with situation); z-axis: a uniquely-encoded set of actions (one set per each category). 

Such encoding ensures complete coverage, is compact and is easy to operate upon. Every point in the 4D array corresponds to some action, in some action-class, on some planet or some fleet, in some future move. In each hypothesis, the x and y-values (number of moves, action categories) will always be fixed, the w-values will change in accordance with how many planets the player owns, and the only thing that can mutate are z-values (according to some restrictions, of course).

'''''Generations and Mutation:'''''

The GA algorithm will start with an init_seed, which is a hypothesis. At the start of the game the init_seed will be determined by the OSM, which will provide a decent strategy to build on (to save on overhead costs on running the algorithm from random values. Note that the init_seed will probably mutate beyond recognition when run through enough generations).  So basically, the starting point of the optimization process would already be a commonsense and reasonable solution. Then, at each subsequent turn, the winning hypothesis of the previous turn will be modified to serve as the next turn's init_seed. The modification will be as follows: shift all 3D <y,z,w> slices one to the left on the x-axis; generate the last one using OSM. In simpler words, I take last turn's winning hypothesis, shift it a move down, and attach a commonsense solution as the last move's set of actions. Again, this is done to minimize overhead, and it will still retain creativity beyond the OSM heuristic paradigm.

The init_seed will then mutate, such that the z-values will mutate in several random points, with compliance to restrictions, to create 3 generation_seeds. At the beginning of each generation, there will be 3 generation_seeds, to preserve a variety of solutions, but on the other hand, not be too computationally-heavy. From each such generation_seed there will evolve three populations: a risk population (high mutation-rate, to seek solutions outside the local maximum), a normal population (moderate mutation rate, with reasonable search-power of solutions), and a conservative population (low mutation rate, to preserve good solutions). Then, each hypothesis will be decoded, simulated, and evaluated. From each population, the best hypothesis will make it to the next selection (9 in all). To prevent loss of good solutions, the generation_seeds will automatically be added to this round of selection (total: 12). Then, the 3 best ones will be selected as the next generation_seeds. 

The process of making new generations will happen a fixed number of times (for a fixed and reasonable execution-time), or until some hypothesis promises a win, and at the end returns the best one. I will have to play around with the numbers, to have the AI take less than 1 to 2 minutes to complete its turn. Then, the actions specified in the first move of the winning hypothesis are sent back to the server for execution.

'''''Fitness function (Hypothesis-assessment):'''''

A fitness function will be derived to give each hypothesis a numeric evaluation, by which they can be compared (e.g. higher = better, or closer to zero = better). This function will have as parameters the current stats of the AI player, its relative standing in the universe compared to others (number of planets, fleets, etc), and the winning conditions of the ruleset in question (here, RFTS). A heuristic will have to be used, as the information available to the player will be incomplete.


'''User Interface'''

I wish to make the AI-agent as fully configurable as possible. Although it is impossible to deterministically predict and influence its behavior, some important features can be played around with:
*Difficulty: This can simply be a function of search depth of the generated hypotheses, of the size of the generation, and/or of the number of generations the algorithm will go through, before outputting a solution.
*Changes to the three OSM's the algorithm will be simulating games against, which will alter the characteristics of the simulated opponents. This can be useful if a player wants a serious challenge. In that case, the player would tweak the opponent-module to play similarly to him(her).

The UI can either be text or GUI. A console command-line interface will serve as the base for all communication with the AI Client, but if time permits I can definitely include the option to have a console command, which invokes a GUI, for increased convenience. An important note is that I only see usefulness in a UI prior to game start, so there is no reason to keep it running during the game. Perhaps some ideas as to the usefulness of in-game communication with the AI player will surface during development.

== Future Directions for ''Genetic Conquest'' ==

Endless work can be put in optimizing an optimization algorithm :). The most interesting and promising directions for future work I can see from this disadvantaged point are:

*OSM (Opponent Simulation Module) Optimization: Quite possibly the most interesting and useful direction to consider, it to provide the OSM with advanced machine-learning capabilities, directed at analyzing visible opponent behavior. This will highly optimize the selection process of hypotheses, since the games being simulated will be with opponents very similar in behavior to real ones. To that end, neural nets could be used for a robust and generic solution. ''I would be very interested in conducting further work in that avenue!''
*Evolutionary Paradigm Optimization: The above process of natural selection is robust and efficient, but it is far from perfect. Even more creative solutions can be found, for example combining evolution and dynamic tree structures, as in having each solution thus generated branch off into separate evolutionary branches, and have a dynamic tree-structure to look n-deep, and find if a branch is worth pursuing. This creates much memory overhead, but increases the originality of solutions. Note: this suggestion is _not_ the alternative mentioned earlier, since it too considers and evaluates move-sequenecs as a whole.
*Ruleset Compliance: I intend for the design to be highly modular, so that it would be straightforward to have the AI agent comply to different rulesets. Probably the best option would be to create a library for each such ruleset, and modify some aspects of the AI accordingly (i.e. the Fitness function, define permissible actions, OSM restrictions and characteristics, and other small things, which will become clearer during implementation).
*Other? As far as I can see, these are the main avenues for improvement, although as I said above, you can work forever on optimizing an optimization algorithm.

== About me ==

My name is Victor Ivri (forum and IRC: vi1985). I'm double majoring in Computer science and Cognitive science at York U, Toronto, Canada. My main interest is in the area of AI. I'm interested in both practical implementations of various forms of AI (probabilistic logic, neural nets, and genetic algorithms, to be specific), and in the philosophical and psychological underpinnings of it. I heard of genetic algorithms some time ago in a Cognitive science conference, ran home, read about how it's done, and built a few (increasingly elaborate) examples myself. I'm really excited at this opportunity to participate in the development process of a 4X game, since I'm a huge fan of both TBS and RTS. I don't have a lot of time for game-playing at the moment, but I still occasionally meet with friends to play HMM3 into the night (or morning) :). 

I possess solid Java development skills (+2 years Java coding) in both Windows and Linux environments, a strong abstraction and problem solving ability, consider myself a good communicator, and above all, I have a very, very strong desire to succeed in this project, to learn, and to grow professionally as an AI developer, and as a member in the opensource community. Although I have rather limited experience in designing client/server applications, I _will_ learn everything that is necessary for it by the end of April, at which point it will become a non-issue.

I want to do this project because it is very interesting and challenging. It is a great opportunity for me to advance my knowledge base and practical skills in my area of interest, as well as gain experience in the opensource community, and I will work very hard to achieve a successful and working result before the deadline. In the time elapsed since I first heard of TP, I've had the pleasure to talk and exchange ideas with many of you, and I hope that our collaboration will continue into the future, since the above project is definitely a something I (and others) can build and elaborate on. Even more than that, I hope that you give me a chance to prove that my ideas and skills are an asset to Thousand Parsec.


'''Programming Example''': 
Here's a rather simple, but neat, example of genetic programming (a day's worth of hacking), which solves a class of non-trivial problems in arithmetic. It is of a quite different design than explained above, but it illustrates how "letting evolution run its course" can solve non-trivial problems. Here is the link: [http://www.4shared.com/account/file/41671485/10b80908/genArithmetic.html]. I have started slowly working on a checkers AI that implements the design above for testing purposes, but I'm afraid it won't be ready soon due to university workload.

'''Contact info''': victor.ivri AT gmail DOT. com


Thank you for considering my candidacy.

== Your Comments Here ==

Very nice proposal, the design is explained in quite a lot of detail. I think in the application you will submit thru the Google webform you can shorten it and make it more compact, but it is great to have it like this on the wiki.

You should also make timeline a bit more detailed in the application and describe GUI a bit more. A some kind of risk management section should also be there: what kind od problems could arise (in coding, life) and what are your plans to deal with these problems.

You also mention that you have already done some examples. It would be a plus if you could provide a link to the source code or examples.

Into application you could also include information if you already have a blog or some other page where you would write about your progress.

Oh yeah and write down what benefits your project brings to TP and game players. Also mention in the application how many hours a week you will be working on this and if you have any other commitments during GSoC period, Maybe you will be on vacation for a few days?

I think this is enough for now from my part. Keep up the great work!
--[[User:JLP|JLP]] 11:13, 23 March 2008 (EDT)

>>>Thank you for your suggestions, JLP. I will put some source code online, and expand on the areas that you mentioned. --[[User:Vi1985|Vi1985]] 11:59, 23 March 2008 (EDT)

>>>Done. --[[User:Vi1985|Vi1985]] 16:12, 23 March 2008 (EDT)


"there is a hard-coded number of players, which must participate in the game"

- Not exactly. This is true of the standard RFTS but is one of the differences for TP RFTS- it has no min players, only a max. Btw, I've made trivial updates to the TP RFTS wiki page.
--[[User:Xdotx|Xdotx]] 21:01, 24 March 2008 (EDT)

>>>Xdotx: Thanks for the update! I have actually caught it about 30mins ago, and made a comment about it in my Google proposal ;). I should change it here as well... --[[User:Vi1985|Vi1985]] 21:31, 24 March 2008 (EDT)

'''Nash''': 

* You mention game performance rating: 
** How is this done?
* Have you had a look at the status of libproto-java?
** Does it do what you need, is it in a good enough status to use?
** Have you taken into account you need to be using it heavily?
* Java:
** What version?
** What platform(s) will you be testing on?
* Training: 
** How long do you expect it to train a decent AI, or even an AI that can play the game?
** Are you going to deliver working AIs?
* Are AIs going to train themselves continually throughout the game? 
** Are they going to be able to stay viable in this case?  Or if they don't train?
* Fitness Space
** You define a 4D fitness space.  Is this really enough?  How about more complex games like a Stars! ruleset?