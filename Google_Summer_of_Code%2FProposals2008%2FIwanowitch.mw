==Proposed project==
The aim of the project is to create an AI client that plays a game of RFTS and manages to provide a challenge for players. There are some points in this proposal that need motivation.

First, why focus only on one ruleset? While it would be an interesting experiment to create a client that can play any ruleset in a competitive way, such a client would probably need to use learning algorithms to adapt to the particular game it is playing. Personally, having some (classroom) experience with probabilistic learning, genetic algorithms and data mining techniques, I believe it would be very hard to create a rule-agnostic AI that can play a reasonable game, even after a reasonable amount of training. Therefore, I'll only aim at one specific ruleset.

Why Reach For The Stars? It is an interesting ruleset gameplay-wise, and I believe it deserves to be one of the showcases of the TP project. As my limited experiments have quickly pointed out to me, though, this ruleset is not 100% complete and bug free. While this might slow down the creation of an AI for the game, there is also another way to look at it: the process of creating an AI will probably expose many bugs and possibly even balancing issues or inconsistencies in the ruleset. Tyler Shaub (xdotx), the creator of RFTS, already mentioned he would be working closely together with whoever else does something with his ruleset - I would definitely keep him to this promise if I'm developing the AI. Thus, this project would almost certainly have a beneficial effect on the stability and polish of RFTS.

Onwards to more technical details. I would code the bot in Python. First, because there is quite some existing and well-tested Python code in the project and I don't think it would add a lot to recreate all that stuff in yet another language. This project would either base the bot off libtpclient-py or the existing AI code in tpsai-py if it can be reused. Secondly, Python is a pretty high-level language - I feel more for Python than for C++, personally. Thirdly, I have to admit I don't know that much Python myself, but I've been thinking about learning it. This project would force me to do so, which I'd see as a tremendous personal gain: I'd finally be able to make up my mind on the Perl vs Python debate (don't mention Ruby). :)

I think game AI is of highest quality when the high-level algorithms are simple and deterministic. I don't know whether to blame difficult debugging, inappropriate techniques or just not enough experimentation of game developers, but I never witnessed a good "messy" game AI. I think there is a reason why most commercial games still have rule-based or finite-state AIs: they are of a much higher quality. As such, I would like to keep to the "KISS" paradigm. The basic AI will consist of a set of weighted and parametrized rules that will aid the bot in deciding what to do next. Rules are to be things like "When under attack, build more ships" or "If you have X resource points left and these conditions are fulfilled, start developing the next technology level". These rules will be hand-crafted after careful research of the rules and some playing practice. It should, however, be easy to add new rules.

Furthermore, these rules will be parametrized (spend X% on industry) and weighted (90% chance to attack, 10% to flee when under attack). These values will be external to the rules to allow easy tweaking of them. It would be possible to easily create a defensive or a technocratic AI using these numbers.

All this isn't too hard, so if time permits it, I would like to play around a bit with these parameters.  Basically, my idea was to use a genetic algorithm to refine the parameters. The ruleset provides a natural fitness function in terms of victory points, evaluation would be to let each AI play some games of RTFS against other AIs. The aim of this approach would not be to find the best possible AI (which I don't believe to exist), but instead to quickly explore the space of possible behaviours of the class of AIs proposed here, and to select some local optima, hopefully coinciding with interesting and differing behavior between AIs. If I can work out a good representation of the rules (unfortunately, I don't have my textbook with me right now - I'm sure I could find some inspiration in it), it might even be possible to add them to the genetic algorithm, too, resulting in an even bigger class of AIs.

Where possible, the design of the AI will be generalized to a framework to ease further development for AIs for other rulesets. However, I'd rather have a working semi-reusable AI than thinking 2 months about a program structure that doesn't work out. Now, don't fear that I'll deliver a heap of spaghetti, I do know my way in good program design. To name a few, Liskov, GRASP and unit tests are part of my mindset when programming.

==Schedule==
I'll try to make a conservative schedule here. When I did SoC last year, it turned out I worked way faster than my schedule. However there were also more periods of down-time than I planned so it worked out pretty well in the end. :)

Before SoC I'll probably be working on a KDE project I want in for KDE 4.1. Don't fear, it shouldn't take much time away from this project. In fact, while I'm busy coding, I'll probably be on IRC so that counts for "community bonding" :). I'll also get my Python skills on a working level, and as a test for this I'll look at the existing Python code in TP until it feels natural to me.

First month of SoC might see not too much work, sorry. I've got some big school project deadlines, a friend to visit abroad, exams during June, and a week off with student's organization (so-called "predisium") to discuss things for next year. However, experience learns that exams often are an excellent time to work on all things non-school related (I'll leave the why to psychologists) - things like SoC. Since my exams shouldn't be too hard in June, that'll be okay. I would like to have at least an AI that has knowledge of the game world (which should be easy seeing the code that already exists), and a solid idea of how my rule engine is going to look in Python by the end of June. It might be possible I don't have much to show off by then - if so, I trust my mentor to evaluate my progress by the amount of sense I make when discussing my ideas with him.

A week into July or something, I should have loads and loads of time to work on the project. Including a few weeks for debugging and testing, I would like to have the AI basically working at the end of July.

August primarily serves as buffer period when things are spinning horribly out of control. If it all goes good, I will use the extra time to tweak the parameters using genetic algorithms, as discussed above. If I *still* have time left, I will try to refactor the design of the AI to extract a framework for possible future AIs for other rulesets.

==Bio==
I'm a 21 year old Belgian student at the K.U. Leuven. I have finished my bachelor's degree in mathematics and am currently studying for a master's degree in informatics with specialization in AI. This means I have broad understanding of many things maths- and computer-related, from Galois fields and error correcting codes to the Mahalanobis distance and data mining. I also have plenty of practical programming experience, working on school projects with 50 pages of design docs, hobby programming like IRC bots and small games (none really enjoyable :), and perhaps most relevant, Summer of Code 2007 where I successfully completed a Kross/Java binding for KDE under the mentorship of Sebastian Sauer.

==Discussion==
