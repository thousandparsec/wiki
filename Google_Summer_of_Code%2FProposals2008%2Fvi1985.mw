== '''''Genetic Conquest''' (henceforth, GC)'', an AI Client for Thousand Parsec: Proposal ==

This document should provide a general overview of the initial design concept of the AI client (GC) I want to design for TP. The AI agent will build on, and integrate with the libtpproto-java library, and hence will be written in Java as well. Upon completion, the AI Client will be able to successfully play the RFTS ruleset, and with slight modifications to its Ruleset module (description follows below), GC will be able to play any other TP ruleset.

*Please feel free to make suggestions/corrections in the discussion section, and in the space provided below!!

== Timeline (Checkpoints) ==

*April 12 - My exams finish; Begin active study of libraries, ruleset, and other relevant materials.
*April-May - Finalize the design scheme.
*mid-May - Start coding.
*July 7 - Have AI agent ready in time for mid-term evaluations.
*August 11 - Complete AI agent-client library integration, and have a buffer week for "pencils down" date.


== Goals ==

*Design and implement the AI agent for TP.
*Integrate it with the libtpproto-java library.
*Collaborate on completing the libtpproto-java library with jezuch.
*Create a convenient and comprehensive UI for the AI client.


== Design Principles ==

'''General Execution Sequence:'''

* Turn start: receive "universe-picture" from server.
* Extract info from the universe picture.
* Compare with previous universe-picture, and generate a prediction of opponent actions.
* Run core genetic algorithm, which would return the set of actions to be performed this turn.
* Communicate actions back to server.


'''Core genetic algorithm'''

I chose a genetic algorithm (GA) for the implementation of the AI agent for several reasons. First of all, they are perfectly suited for the role in TBS games, since they involve a progressive refinement of "hypotheses", basically move-sequences, then returning a suitable "hypothesis", and not on-the-go split-second heuristic decisions. Since it is looking many moves ahead, the solutions it comes up with aren't "quick-fixes", but genuine strategy. Together a heuristic to predict opponent-moves, this algorithm will make the AI relatively sensitive to traps, and hard to fool. Another bonus is that the solutions it comes up with, will be genuinely creative ones, since there will be no hard-coded templates, or even heuristics, on which it will rely in decision making. This will ensure that it will always be a creative and unpredictable opponent! :-) Finally, a GA design will make the algorithm highly modular, and ensure quick transitions between rulesets. The main difficulty I expect to encounter, will be in making a good heuristic for predicting enemy moves. Careful analysis will have to be done to estimate what should a player do, based on its assets, and the positioning on the map relative to others. Then a small set of rules (possibly probabilistic ones!) will be extracted, and implemented as the "opponent-predictor" module.

'''The Evolutionary Paradigm'''

The GA will operate on "hypotheses", which are basically encoded move-sequences. Each such hypothesis will be a 3D array (x-axis: each move (1... search_depth); y-axis: move categories (1...last_category), e.g. development, purchasing, etc.; z-axis: a uniquely-encoded set of moves (1...m) ). Such encoding ensures complete coverage, is compact and is easy to operate upon. In each hypothesis, the x and y axes (number of moves, move categories) will be fixed, and the only thing that will change will be 




    * For each generated hypothesis:
      * init: generate dummy_universe = current_universe;
      * For each move, while move.index < search_depth do: simulate move in dummy_universe, then simulate opponent moves based on previous prediction;
      * when move.index = search.depth do: evaluate hypothesis based on fitness function;
    * When finished evolution process, return best hypothesis.
